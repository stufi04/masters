{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1. #what portion of gpu to use\n",
    "session = tf.Session(config=config)\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, Add, Lambda, add\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D, concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from skimage.io import imread\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "classes = ['BUBBLES_v3','CLEAR_BLOB','DILATED','TURBID_v2','UNDEFINED','WALL','WRINKLES_v2']\n",
    "#classes = ['BUBBLES_v3','CLEAR_BLOB','DILATED','UNDEFINED','WALL','WRINKLES_v2']\n",
    "mainDir = '/data/intestins/original/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_per_class = 1000\n",
    "img_per_test = 100\n",
    "cls = 0\n",
    "X_train = np.empty([7*img_per_class,256,256,3])\n",
    "y_train = np.zeros([7*img_per_class])\n",
    "X_test = np.empty([7*img_per_test,256,256,3])\n",
    "y_test = np.zeros([7*img_per_test])\n",
    "for c in classes:\n",
    "    cnt = 0\n",
    "    curDir = mainDir + c\n",
    "    pathlist = Path(curDir).glob('*')\n",
    "    for path in pathlist:\n",
    "        path_str = str(path)\n",
    "        if \"png\" not in path_str and \"jpg\" not in path_str and \"bmp\" not in path_str:\n",
    "            continue\n",
    "        if \"r180\" in path_str or \"r90\" in path_str:\n",
    "            continue\n",
    "        im = imread(path_str)\n",
    "        imarray = np.array(im)\n",
    "        imresized = resize(imarray, (256,256), mode='symmetric')\n",
    "        if cnt >= img_per_class + img_per_test:\n",
    "            break\n",
    "        elif cnt >= img_per_class:\n",
    "            X_test[cls * img_per_test + cnt - img_per_class] = imresized\n",
    "            y_test[cls * img_per_test + cnt - img_per_class] = cls\n",
    "        else:\n",
    "            X_train[cls * img_per_class + cnt] = imresized\n",
    "            y_train[cls * img_per_class + cnt] = cls\n",
    "        cnt += 1\n",
    "    cls += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on code by Rowel Atienza (https://github.com/roatienza/Deep-Learning-Experiments)\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Reshape\n",
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "#config = tf.ConfigProto()\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4 #what portion of gpu to use\n",
    "#session = tf.Session(config=config)\n",
    "#keras.backend.set_session(session)\n",
    "\n",
    "class ElapsedTimer(object):\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "    def elapsed(self,sec):\n",
    "        if sec < 60:\n",
    "            return str(sec) + \" sec\"\n",
    "        elif sec < (60 * 60):\n",
    "            return str(sec / 60) + \" min\"\n",
    "        else:\n",
    "            return str(sec / (60 * 60)) + \" hr\"\n",
    "    def elapsed_time(self):\n",
    "        print(\"Elapsed: %s \" % self.elapsed(time.time() - self.start_time) )\n",
    "\n",
    "class DCGAN(object):\n",
    "    def __init__(self, img_rows=64, img_cols=64, channel=3):\n",
    "\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "        self.channel = channel\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channel)\n",
    "        self.num_classes = 7\n",
    "        self.D = None   # discriminator\n",
    "        self.G = None   # generator\n",
    "        self.AM = None  # adversarial model\n",
    "        self.DM = None  # discriminator model\n",
    "\n",
    "    # (Wâˆ’F+2P)/S+1\n",
    "    def discriminator(self):\n",
    "        \n",
    "        depth = 64\n",
    "        dropout = 0.2\n",
    "        \n",
    "        img = Input(shape=self.img_shape)\n",
    "        \n",
    "        label = Input(shape=(1,))\n",
    "        label_embedding = Flatten()(Embedding(self.nclasses, self.latent_dim)(label))\n",
    "        d1 = Dense(512, activation=\"relu\")(label_embedding)\n",
    "        d2 = Dense(4096, activation=\"relu\")(d1)\n",
    "        label_img_shape = Reshape((64,64,1))(d2)\n",
    "        \n",
    "        new_img = concatenate([img, label_img_shape], axis=3)\n",
    "        \n",
    "        c1 = Conv2D(depth, 5, strides=2, padding='same')(new_img)\n",
    "        c1 = LeakyReLU(alpha=0.2)(c1)\n",
    "        c1 = Dropout(dropout)(c1) # 32 x 32 x 64\n",
    "        \n",
    "        c2 = Conv2D(depth, 5, padding='same')(c1)\n",
    "        c2 = LeakyReLU(alpha=0.2)(c2)\n",
    "        c2 = Dropout(dropout)(c2) # 32 x 32 x 64\n",
    "        \n",
    "        c3 = Conv2D(depth, 5, padding='same')(c2)\n",
    "        c3 = LeakyReLU(alpha=0.2)(c3)\n",
    "        c3 = Dropout(dropout)(c3) # 32 x 32 x 64\n",
    "        \n",
    "        c4 = Conv2D(depth, 5, padding='same')(c3)\n",
    "        c4 = LeakyReLU(alpha=0.2)(c4)\n",
    "        c4 = Dropout(dropout)(c4) # 32 x 32 x 64\n",
    "        \n",
    "        a1 = Add()([c1, c4])\n",
    "           \n",
    "        c5 = Conv2D(depth*2, 5, strides=2, padding='same')(a1)\n",
    "        c5 = LeakyReLU(alpha=0.2)(c5)\n",
    "        c5 = Dropout(dropout)(c5) # 16 x 16 x 128\n",
    "        \n",
    "        c6 = Conv2D(depth*2, 5, padding='same')(c5)\n",
    "        c6 = LeakyReLU(alpha=0.2)(c6)\n",
    "        c6 = Dropout(dropout)(c6) # 16 x 16 x 128\n",
    "        \n",
    "        c7 = Conv2D(depth*2, 5, padding='same')(c6)\n",
    "        c7 = LeakyReLU(alpha=0.2)(c7)\n",
    "        c7 = Dropout(dropout)(c7) # 16 x 16 x 128\n",
    "        \n",
    "        c8 = Conv2D(depth*2, 5, padding='same')(c7)\n",
    "        c8 = LeakyReLU(alpha=0.2)(c8)\n",
    "        c8 = Dropout(dropout)(c8) # 16 x 16 x 128\n",
    "        \n",
    "        a2 = Add()([c5, c8])\n",
    "        \n",
    "        c9 = Conv2D(depth*4, 5, strides=2, padding='same')(a2)\n",
    "        c9 = LeakyReLU(alpha=0.2)(c9)\n",
    "        c9 = Dropout(dropout)(c9) # 8 x 8 x 256\n",
    "        \n",
    "        c10 = Conv2D(depth*4, 5, padding='same')(c9)\n",
    "        c10 = LeakyReLU(alpha=0.2)(c10)\n",
    "        c10 = Dropout(dropout)(c10) # 8 x 8 x 256\n",
    "        \n",
    "        c11 = Conv2D(depth*4, 5, padding='same')(c10)\n",
    "        c11 = LeakyReLU(alpha=0.2)(c11)\n",
    "        c11 = Dropout(dropout)(c11) # 8 x 8 x 256\n",
    "        \n",
    "        c12 = Conv2D(depth*4, 5, padding='same')(c11)\n",
    "        c12 = LeakyReLU(alpha=0.2)(c12)\n",
    "        c12 = Dropout(dropout)(c12) # 8 x 8 x 256\n",
    "        \n",
    "        a3 = Add()([c9, c12])\n",
    "        \n",
    "        c13 = Conv2D(depth*8, 5, strides=2, padding='same')(a3)\n",
    "        c13 = LeakyReLU(alpha=0.2)(c13) # 4 x 4 x 512\n",
    "\n",
    "        f = Flatten()(c13)\n",
    "        \n",
    "        validity = Dense(1)(f)\n",
    "        \n",
    "        self.D = Model(inputs=[img,label], output=validity)\n",
    "        self.D.summary()\n",
    "        return self.D\n",
    "        \n",
    "    \n",
    "    def generator(self):\n",
    "        \n",
    "        dropout = 0.4\n",
    "        depth = 256\n",
    "        dim = 8\n",
    "        \n",
    "        noise = Input(shape=(self.latent_dim,))    \n",
    "        label = Input(shape=(1,))   \n",
    "        label_embedding = Flatten()(Embedding(self.nclasses, self.latent_dim)(label))\n",
    "        model_input = concatenate([noise, label_embedding])\n",
    "        \n",
    "        # In: 100\n",
    "        # Out: dim x dim x depth\n",
    "        d = Dense(dim*dim*depth, activation=\"relu\")(model_input)\n",
    "        d = BatchNormalization(momentum=0.9)(d)\n",
    "        d = Reshape((dim, dim, depth))(d) # 8 x 8 x 256\n",
    "\n",
    "        # In: dim x dim x depth\n",
    "        # Out: 2*dim x 2*dim x depth/2\n",
    "        u1 = UpSampling2D()(d) # 16 x 16 x 256\n",
    "        \n",
    "        c1 = Conv2DTranspose(int(depth/2), 5, padding='same', activation=\"relu\")(u1) # 16 x 16 x 128\n",
    "        c1 = BatchNormalization(momentum=0.9)(c1)\n",
    "        \n",
    "        c2 = Conv2DTranspose(int(depth/2), 5, padding='same', activation=\"relu\")(c1) # 16 x 16 x 128\n",
    "        c2 = BatchNormalization(momentum=0.9)(c2)\n",
    "        \n",
    "        c3 = Conv2DTranspose(int(depth/2), 5, padding='same', activation=\"relu\")(c2) # 16 x 16 x 128\n",
    "        c3 = BatchNormalization(momentum=0.9)(c3)\n",
    "        \n",
    "        c4 = Conv2DTranspose(int(depth/2), 5, padding='same', activation=\"relu\")(c3) # 16 x 16 x 128\n",
    "        c4 = BatchNormalization(momentum=0.9)(c4)\n",
    "        \n",
    "        a1 = Add()([c1, c4])\n",
    "        u2 = UpSampling2D()(a1) # 32 x 32 x 128\n",
    "        \n",
    "        c5 = Conv2DTranspose(int(depth/4), 5, padding='same', activation=\"relu\")(u2) # 32 x 32 x 64\n",
    "        c5 = BatchNormalization(momentum=0.9)(c5)\n",
    "        \n",
    "        c6 = Conv2DTranspose(int(depth/4), 5, padding='same', activation=\"relu\")(c5) # 32 x 32 x 64\n",
    "        c6 = BatchNormalization(momentum=0.9)(c6)\n",
    "        \n",
    "        c7 = Conv2DTranspose(int(depth/4), 5, padding='same', activation=\"relu\")(c6) # 32 x 32 x 64\n",
    "        c7 = BatchNormalization(momentum=0.9)(c7)\n",
    "        \n",
    "        c8 = Conv2DTranspose(int(depth/4), 5, padding='same', activation=\"relu\")(c7) # 32 x 32 x 64\n",
    "        c8 = BatchNormalization(momentum=0.9)(c8)\n",
    "        \n",
    "        a2 = Add()([c5, c8])\n",
    "        u3 = UpSampling2D()(a2) # 64 x 64 x 64\n",
    "        \n",
    "        c9 = Conv2DTranspose(int(depth/8), 5, padding='same', activation=\"relu\")(u3) # 64 x 64 x 32\n",
    "        c9 = BatchNormalization(momentum=0.9)(c9)\n",
    "        \n",
    "        c10 = Conv2DTranspose(int(depth/8), 5, padding='same', activation=\"relu\")(c9) # 64 x 64 x 32\n",
    "        c10 = BatchNormalization(momentum=0.9)(c10)\n",
    "        \n",
    "        c11 = Conv2DTranspose(int(depth/8), 5, padding='same', activation=\"relu\")(c10) # 64 x 64 x 32\n",
    "        c11 = BatchNormalization(momentum=0.9)(c11)\n",
    "        \n",
    "        c12 = Conv2DTranspose(int(depth/8), 5, padding='same', activation=\"relu\")(c11) # 64 x 64 x 32\n",
    "        c12 = BatchNormalization(momentum=0.9)(c12)\n",
    "        \n",
    "        a3 = Add()([c9, c12])\n",
    "\n",
    "        # Out: 28 x 28 x 1 grayscale image [0.0,1.0] per pix\n",
    "        generated_img = Conv2DTranspose(3, 5, padding='same')(a3) # 64 x 64 x 3\n",
    "        \n",
    "        self.G = Model(inputs = [noise, label], output = generated_img) \n",
    "        self.G.summary()\n",
    "        return self.G \n",
    "\n",
    "    def discriminator_model(self):\n",
    "        if self.DM:\n",
    "            return self.DM\n",
    "        \n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "        self.DM = self.discriminator()\n",
    "        self.DM.compile(loss=wasserstein_loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        return self.DM\n",
    "\n",
    "    def adversarial_model(self):\n",
    "        if self.AM:\n",
    "            return self.AM\n",
    "        \n",
    "        optimizer = RMSprop(lr=0.00005)\n",
    "        \n",
    "        D = self.discriminator()\n",
    "        G = self.generator()\n",
    "        \n",
    "        noise = Input(shape=(100,))\n",
    "        label = Input(shape=(1,))\n",
    "        img = G([noise, label])\n",
    "        valid = D([img, label])\n",
    "        \n",
    "        self.AM = Model([noise, label], valid)\n",
    "        self.AM.compile(loss=wasserstein_loss, optimizer=optimizer)\n",
    "        \n",
    "        #self.AM.compile(optimizer='RMSprop', loss=custom_loss)\n",
    "        return self.AM\n",
    "\n",
    "class MNIST_DCGAN(object):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        self.img_rows = 64\n",
    "        self.img_cols = 64\n",
    "        self.channel = 3\n",
    "        \n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "        self.DCGAN = DCGAN()\n",
    "        self.discriminator =  self.DCGAN.discriminator_model()\n",
    "        self.adversarial = self.DCGAN.adversarial_model()\n",
    "        self.generator = self.DCGAN.generator()\n",
    "\n",
    "        \n",
    "    def train(self, train_steps=2000, batch_size=256, save_interval=0):\n",
    "        \n",
    "        history_d = []\n",
    "        history_a = []\n",
    "        history_acc = []\n",
    "        \n",
    "        noise_input = None\n",
    "        if save_interval>0:\n",
    "            noise_input = np.random.uniform(-1.0, 1.0, size=[35, 100])\n",
    "            \n",
    "        for epoch in range(train_steps):    \n",
    "\n",
    "            idx = np.random.permutation(self.x_train.shape[0])\n",
    "            X_train = self.x_train[idx]\n",
    "            y_train = self.y_train[idx]\n",
    "            \n",
    "            steps = math.ceil(X_train.shape[0]/batch_size)\n",
    "            \n",
    "            for i in range(steps):\n",
    "                \n",
    "                if (i%3 == 2):\n",
    "                    \n",
    "                    history_d.append(d_loss[0])\n",
    "                    history_acc.append(d_loss[1])\n",
    "                    \n",
    "                    # freeze D\n",
    "                    self.discriminator.trainable = False\n",
    "                    for l in self.discriminator.layers:\n",
    "                        l.trainable = False\n",
    "\n",
    "                    # train adverserial model\n",
    "                    y = np.ones([batch_size, 1])\n",
    "                    noise = np.random.uniform(-1.0, 1.0, size=[batch_size, 100])\n",
    "                    sample_labels = np.random.randint(0, 7, batch_size).reshape(-1, 1)\n",
    "\n",
    "                    a_loss = self.adversarial.train_on_batch([noise, sample_labels], y)\n",
    "                    history_a.append(a_loss)\n",
    "                    \n",
    "                    # unfreeze D\n",
    "                    self.discriminator.trainable = True\n",
    "                    for l in self.discriminator.layers:\n",
    "                        l.trainable = True\n",
    "                        \n",
    "\n",
    "                # clip D weights\n",
    "                for l in self.discriminator.layers:\n",
    "                    weights = l.get_weights()\n",
    "                    weights = [np.clip(w, -0.01, 0.01) for w in weights]\n",
    "                    l.set_weights(weights)\n",
    "            \n",
    "                images_train = X_train[i*batch_size:min((i+1)*batch_size,X_train.shape[0])]\n",
    "                labels = y_train[i*batch_size:min((i+1)*batch_size,X_train.shape[0])]\n",
    "                \n",
    "                cur_batch_size = images_train.shape[0]\n",
    "                \n",
    "                noise = np.random.uniform(-1.0, 1.0, size=[cur_batch_size, 100])\n",
    "                images_fake = self.generator.predict([noise, labels])\n",
    "                \n",
    "                x = np.concatenate((images_train, images_fake))\n",
    "                ls = np.concatenate([labels, labels])\n",
    "                y = np.ones([2*cur_batch_size, 1])\n",
    "                y[cur_batch_size:, :] = -1\n",
    "                \n",
    "                d_loss = self.discriminator.train_on_batch([x, ls], y)       \n",
    "            \n",
    "            log_mesg = \"%d: [D loss: %f, acc: %f]\" % (epoch, d_loss[0], d_loss[1])\n",
    "            log_mesg = \"%s  [A loss: %f]\" % (log_mesg, a_loss)\n",
    "            print(log_mesg)\n",
    "            \n",
    "            if save_interval>0:\n",
    "                if (epoch+1)%save_interval==0:\n",
    "                    self.plot_images(save2file=True, samples=noise_input.shape[0],\\\n",
    "                        noise=noise_input, step=(epoch+1))\n",
    "                    \n",
    "        return history_d, history_a, history_acc\n",
    "\n",
    "\n",
    "    def plot_images(self, save2file=False, fake=True, samples=35, noise=None, step=0):\n",
    "        filename = 'intestines_cgan/mnist.png'\n",
    "        if fake:\n",
    "            if noise is None:\n",
    "                noise = np.random.uniform(-1.0, 1.0, size=[samples, 100])\n",
    "            else:\n",
    "                filename = \"intestines_cgan/mnist_%d.png\" % step\n",
    "            sample_labels = np.repeat(np.arange(7),samples/7)\n",
    "            images = self.generator.predict([noise, sample_labels])\n",
    "        else:\n",
    "            i = np.random.randint(0, self.x_train.shape[0], samples)\n",
    "            images = self.x_train[i, :, :, :]\n",
    "\n",
    "        plt.figure(figsize=(12,15))\n",
    "        for i in range(images.shape[0]):\n",
    "            plt.subplot(7, samples/7, i+1)\n",
    "            image = images[i, :, :, :]\n",
    "            image = np.reshape(image, [self.img_rows, self.img_cols, self.channel])\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        if save2file:\n",
    "            plt.savefig(filename)\n",
    "            plt.close('all')\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mnist_dcgan = MNIST_DCGAN(X_train, y_train)\n",
    "    timer = ElapsedTimer()\n",
    "    history_d, history_a, history_acc = mnist_dcgan.train(train_steps=1000, batch_size=250, save_interval=1)\n",
    "    timer.elapsed_time()\n",
    "    mnist_dcgan.plot_images(fake=True)\n",
    "    mnist_dcgan.plot_images(fake=False, save2file=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
